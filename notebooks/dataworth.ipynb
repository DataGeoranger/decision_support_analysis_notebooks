{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data worth and related assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use outputs from previous notebooks (in particular `pestpp-glm_part1.ipynb`) to undertake data worth assessments based on first-order second-moment (FOSM) techniques. \"Worth\" is framed here in the context of the extent to which the uncertainty surrounding a model prediction of management interest is reduced through data collection.  Given that these anayses can help target and optimize data acquisition strategies, this is a concept that really resonates with decision makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:53.358962Z",
     "iopub.status.busy": "2020-11-12T05:56:53.358962Z",
     "iopub.status.idle": "2020-11-12T05:56:54.156821Z",
     "shell.execute_reply": "2020-11-12T05:56:54.156821Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:54.156821Z",
     "iopub.status.busy": "2020-11-12T05:56:54.156821Z",
     "iopub.status.idle": "2020-11-12T05:56:54.174147Z",
     "shell.execute_reply": "2020-11-12T05:56:54.174147Z"
    }
   },
   "outputs": [],
   "source": [
    "m_d = \"master_glm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:54.174147Z",
     "iopub.status.busy": "2020-11-12T05:56:54.174147Z",
     "iopub.status.idle": "2020-11-12T05:56:54.535195Z",
     "shell.execute_reply": "2020-11-12T05:56:54.535195Z"
    }
   },
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(\"freyberg.nam\",model_ws=m_d,check=False,forgive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:54.550871Z",
     "iopub.status.busy": "2020-11-12T05:56:54.550871Z",
     "iopub.status.idle": "2020-11-12T05:56:54.693842Z",
     "shell.execute_reply": "2020-11-12T05:56:54.693842Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot some model attributes\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = plt.subplot(111,aspect=\"equal\")\n",
    "mm = flopy.plot.PlotMapView(model=m)\n",
    "mm.plot_grid()\n",
    "mm.plot_ibound()\n",
    "mm.plot_bc('SFR')\n",
    "mm.plot_bc(\"GHB\")\n",
    "ax = mm.ax\n",
    "#m.wel.stress_period_data.plot(ax=ax,mflay=2)\n",
    "\n",
    "# plot obs locations\n",
    "obs = pd.read_csv(os.path.join(\"..\",\"base_model_files\",\"obs_loc.csv\"))\n",
    "                  \n",
    "obs_x = [m.sr.xcentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "obs_y = [m.sr.ycentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "ax.scatter(obs_x,obs_y,marker='.',label=\"water-level obs\",s=80)\n",
    "\n",
    "#plot names on the pumping well locations\n",
    "wel_data = m.wel.stress_period_data[0]\n",
    "wel_x = m.sr.xcentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "wel_y = m.sr.ycentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "for i,(x,y) in enumerate(zip(wel_x,wel_y)):\n",
    "    ax.scatter([x],[y],color=\"red\",marker=\"s\",s=50)\n",
    "    #ax.text(x,y,\"{0}\".format(i+1),ha=\"center\",va=\"center\")\n",
    "\n",
    "ax.set_ylabel(\"y(m)\")\n",
    "ax.set_xlabel(\"x(m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:54.693842Z",
     "iopub.status.busy": "2020-11-12T05:56:54.693842Z",
     "iopub.status.idle": "2020-11-12T05:56:55.041415Z",
     "shell.execute_reply": "2020-11-12T05:56:55.041415Z"
    }
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"freyberg_pp.pst\"))\n",
    "print(pst.npar_adj)\n",
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first ingredient: parameter covariance matrix (representing prior uncertainty in this instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:55.041415Z",
     "iopub.status.busy": "2020-11-12T05:56:55.041415Z",
     "iopub.status.idle": "2020-11-12T05:56:55.882741Z",
     "shell.execute_reply": "2020-11-12T05:56:55.882741Z"
    }
   },
   "outputs": [],
   "source": [
    "cov = pyemu.Cov.from_binary(os.path.join(m_d,\"prior_cov.jcb\")).to_dataframe()\n",
    "cov = cov.loc[pst.adj_par_names,pst.adj_par_names]\n",
    "cov = pyemu.Cov.from_dataframe(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:55.882741Z",
     "iopub.status.busy": "2020-11-12T05:56:55.882741Z",
     "iopub.status.idle": "2020-11-12T05:56:56.100441Z",
     "shell.execute_reply": "2020-11-12T05:56:56.100441Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's inspect only\n",
    "x = cov.x.copy()\n",
    "x[x<1e-7] = np.nan\n",
    "c = plt.imshow(x)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:56.100441Z",
     "iopub.status.busy": "2020-11-12T05:56:56.100441Z",
     "iopub.status.idle": "2020-11-12T05:56:56.117326Z",
     "shell.execute_reply": "2020-11-12T05:56:56.117326Z"
    }
   },
   "outputs": [],
   "source": [
    "pst.adj_par_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second ingredient: jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:56.117326Z",
     "iopub.status.busy": "2020-11-12T05:56:56.117326Z",
     "iopub.status.idle": "2020-11-12T05:56:56.133262Z",
     "shell.execute_reply": "2020-11-12T05:56:56.133262Z"
    }
   },
   "outputs": [],
   "source": [
    "jco = os.path.join(m_d,\"freyberg_pp.jcb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the third ingredient--the (diagonal) noise covariance matrix--populated on-the-fly using weights when constructing the Schur object below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:56.133262Z",
     "iopub.status.busy": "2020-11-12T05:56:56.133262Z",
     "iopub.status.idle": "2020-11-12T05:56:56.703868Z",
     "shell.execute_reply": "2020-11-12T05:56:56.703868Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(jco=jco,parcov=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:56.703868Z",
     "iopub.status.busy": "2020-11-12T05:56:56.703868Z",
     "iopub.status.idle": "2020-11-12T05:56:56.726341Z",
     "shell.execute_reply": "2020-11-12T05:56:56.726341Z"
    }
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:56.726341Z",
     "iopub.status.busy": "2020-11-12T05:56:56.726341Z",
     "iopub.status.idle": "2020-11-12T05:56:57.268763Z",
     "shell.execute_reply": "2020-11-12T05:56:57.268763Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.get_forecast_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was easy...but maybe not the standard use case.  In many modeling analyses, there will be a separate scenario model - it is this model that will yield the forecast sensitivity vector(s) needed to map parameter uncertainty to forecast uncertainty.  That is, you will need to run the scenario model once for each parameter to fill a separate jacobian -  jacobian that has the same columns as the obervation jacobian, but has rows that are the forecasts.  \n",
    "\n",
    "Now we didnt do that here, but we can \"fake\" it but extracting the forecast rows from the full jacobian and \"pretending\" it is scenario-based forecast jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:57.268763Z",
     "iopub.status.busy": "2020-11-12T05:56:57.268763Z",
     "iopub.status.idle": "2020-11-12T05:56:57.470053Z",
     "shell.execute_reply": "2020-11-12T05:56:57.470053Z"
    }
   },
   "outputs": [],
   "source": [
    "obs_jco = pyemu.Jco.from_binary(jco)\n",
    "obs_jco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:57.470053Z",
     "iopub.status.busy": "2020-11-12T05:56:57.470053Z",
     "iopub.status.idle": "2020-11-12T05:56:57.534441Z",
     "shell.execute_reply": "2020-11-12T05:56:57.534441Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast_jco = obs_jco.get(row_names=pst.forecast_names,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:57.534441Z",
     "iopub.status.busy": "2020-11-12T05:56:57.534441Z",
     "iopub.status.idle": "2020-11-12T05:56:57.564157Z",
     "shell.execute_reply": "2020-11-12T05:56:57.564157Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast_jco.shape,obs_jco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:57.580611Z",
     "iopub.status.busy": "2020-11-12T05:56:57.580611Z",
     "iopub.status.idle": "2020-11-12T05:56:57.627641Z",
     "shell.execute_reply": "2020-11-12T05:56:57.627641Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(pst=pst,jco=obs_jco,forecasts=forecast_jco.T,parcov=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:56:57.627641Z",
     "iopub.status.busy": "2020-11-12T05:56:57.627641Z",
     "iopub.status.idle": "2020-11-12T05:57:02.043086Z",
     "shell.execute_reply": "2020-11-12T05:57:02.043086Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.get_forecast_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go...easy peasy.  What do these results imply about the \"value\" of proceeding with history matching?  Are we justified to continue???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there we have it--all computations done and contained within `sc`.  We will only be required to access different parts of `sc` below...\n",
    "\n",
    "### Parameter uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's inspect the (approx) posterior parameter covariance matrix and the reduction in parameter uncertainty through \"data assimilation\", before mapping to forecasts... (note that this matrix is ${\\it not}$ forecast-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.055401Z",
     "iopub.status.busy": "2020-11-12T05:57:02.053158Z",
     "iopub.status.idle": "2020-11-12T05:57:02.102202Z",
     "shell.execute_reply": "2020-11-12T05:57:02.102202Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.posterior_parameter.to_dataframe().sort_index(axis=1).iloc[100:105:,100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.112249Z",
     "iopub.status.busy": "2020-11-12T05:57:02.102202Z",
     "iopub.status.idle": "2020-11-12T05:57:02.370304Z",
     "shell.execute_reply": "2020-11-12T05:57:02.370304Z"
    }
   },
   "outputs": [],
   "source": [
    "x = sc.posterior_parameter.x.copy()\n",
    "x[x<1e-7] = np.nan\n",
    "c = plt.imshow(x)\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the posterior variance for each parameter along the diagonal. The off-diags are symmetric. a work of art!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.378813Z",
     "iopub.status.busy": "2020-11-12T05:57:02.378813Z",
     "iopub.status.idle": "2020-11-12T05:57:02.394754Z",
     "shell.execute_reply": "2020-11-12T05:57:02.394754Z"
    }
   },
   "outputs": [],
   "source": [
    "par_sum = sc.get_parameter_summary().sort_values(\"percent_reduction\",ascending=False)\n",
    "par_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.394754Z",
     "iopub.status.busy": "2020-11-12T05:57:02.394754Z",
     "iopub.status.idle": "2020-11-12T05:57:02.651513Z",
     "shell.execute_reply": "2020-11-12T05:57:02.651513Z"
    }
   },
   "outputs": [],
   "source": [
    "par_sum.loc[par_sum.index[:25],\"percent_reduction\"].plot(kind=\"bar\",color=\"turquoise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we achieved by \"notionally calibrating\" our model to water levels and fluxes? Which parameters are informed? Will they matter for the forecast of interest? Which ones are un-informed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.651513Z",
     "iopub.status.busy": "2020-11-12T05:57:02.651513Z",
     "iopub.status.idle": "2020-11-12T05:57:02.668386Z",
     "shell.execute_reply": "2020-11-12T05:57:02.668386Z"
    }
   },
   "outputs": [],
   "source": [
    "pst.nnz_obs_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.668386Z",
     "iopub.status.busy": "2020-11-12T05:57:02.668386Z",
     "iopub.status.idle": "2020-11-12T05:57:02.683944Z",
     "shell.execute_reply": "2020-11-12T05:57:02.683944Z"
    }
   },
   "outputs": [],
   "source": [
    "forecasts = sc.pst.forecast_names\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.698240Z",
     "iopub.status.busy": "2020-11-12T05:57:02.698240Z",
     "iopub.status.idle": "2020-11-12T05:57:02.714157Z",
     "shell.execute_reply": "2020-11-12T05:57:02.714157Z"
    }
   },
   "outputs": [],
   "source": [
    "df = sc.get_forecast_summary()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.729604Z",
     "iopub.status.busy": "2020-11-12T05:57:02.729604Z",
     "iopub.status.idle": "2020-11-12T05:57:02.861527Z",
     "shell.execute_reply": "2020-11-12T05:57:02.861527Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a pretty plot \n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax = df[\"percent_reduction\"].plot(kind='bar',ax=ax,grid=True)\n",
    "ax.set_ylabel(\"percent uncertainy\\nreduction from calibration\")\n",
    "ax.set_xlabel(\"forecast\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise, surprise... Some forecasts benefit from calibration, some do not! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before moving onto data worth, let's look at the contribution of different parameters to forecast uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter contributions to uncertainty are quantified by \"fixing\" parameters (or parameter groups) and observing the uncertainty reduction as a result. This approach is of course subject to some sizable assumptions--related to parameter representativeness. But it can be very informative. Let's do by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T05:57:02.871785Z",
     "iopub.status.busy": "2020-11-12T05:57:02.861527Z",
     "iopub.status.idle": "2020-11-12T06:01:37.865995Z",
     "shell.execute_reply": "2020-11-12T06:01:37.865995Z"
    }
   },
   "outputs": [],
   "source": [
    "par_contrib = sc.get_par_group_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:37.876043Z",
     "iopub.status.busy": "2020-11-12T06:01:37.874029Z",
     "iopub.status.idle": "2020-11-12T06:01:37.894123Z",
     "shell.execute_reply": "2020-11-12T06:01:37.896138Z"
    }
   },
   "outputs": [],
   "source": [
    "par_contrib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:37.906186Z",
     "iopub.status.busy": "2020-11-12T06:01:37.896138Z",
     "iopub.status.idle": "2020-11-12T06:01:37.936659Z",
     "shell.execute_reply": "2020-11-12T06:01:37.934638Z"
    }
   },
   "outputs": [],
   "source": [
    "base = par_contrib.loc[\"base\",:]\n",
    "par_contrib = 100.0 * (base - par_contrib) / base\n",
    "par_contrib.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:37.936659Z",
     "iopub.status.busy": "2020-11-12T06:01:37.936659Z",
     "iopub.status.idle": "2020-11-12T06:01:38.593558Z",
     "shell.execute_reply": "2020-11-12T06:01:38.593558Z"
    }
   },
   "outputs": [],
   "source": [
    "for forecast in par_contrib.columns:\n",
    "    fore_df = par_contrib.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance reduction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is the worth of ${\\it existing}$ observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening under the hood is that we are recalculating the Schur complement without some of the observations to see how the posterior forecast uncertainty increases (wrt a \"base\" condition in which we have all observation data available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:38.593558Z",
     "iopub.status.busy": "2020-11-12T06:01:38.593558Z",
     "iopub.status.idle": "2020-11-12T06:01:38.624804Z",
     "shell.execute_reply": "2020-11-12T06:01:38.624804Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pst.nnz_obs_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:38.624804Z",
     "iopub.status.busy": "2020-11-12T06:01:38.624804Z",
     "iopub.status.idle": "2020-11-12T06:01:38.671764Z",
     "shell.execute_reply": "2020-11-12T06:01:38.671764Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.get_obs_group_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:38.685262Z",
     "iopub.status.busy": "2020-11-12T06:01:38.671764Z",
     "iopub.status.idle": "2020-11-12T06:01:45.667299Z",
     "shell.execute_reply": "2020-11-12T06:01:45.667299Z"
    }
   },
   "outputs": [],
   "source": [
    "dw_rm = sc.get_removed_obs_group_importance()\n",
    "dw_rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the ``base`` row contains the results of the Schur complement calculation (in terms of forecast uncertainty variance) using all observations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:45.682716Z",
     "iopub.status.busy": "2020-11-12T06:01:45.682716Z",
     "iopub.status.idle": "2020-11-12T06:01:45.698659Z",
     "shell.execute_reply": "2020-11-12T06:01:45.698659Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's normalize to make more meaningful comparisons of data worth (unctainty variance reduction)\n",
    "base = dw_rm.loc[\"base\",:]\n",
    "dw_rm = 100 * (dw_rm  - base) / base\n",
    "dw_rm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:45.698659Z",
     "iopub.status.busy": "2020-11-12T06:01:45.698659Z",
     "iopub.status.idle": "2020-11-12T06:01:46.405946Z",
     "shell.execute_reply": "2020-11-12T06:01:46.405946Z"
    }
   },
   "outputs": [],
   "source": [
    "for forecast in dw_rm.columns:\n",
    "    fore_df = dw_rm.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance increase\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an option to calculate the worth of observations by taking a \"base\" condition of zero observation (i.e., a priori) and calculating the reduction in uncertainty through adding observations to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:46.405946Z",
     "iopub.status.busy": "2020-11-12T06:01:46.405946Z",
     "iopub.status.idle": "2020-11-12T06:01:53.223133Z",
     "shell.execute_reply": "2020-11-12T06:01:53.223133Z"
    }
   },
   "outputs": [],
   "source": [
    "dw_ad = sc.get_added_obs_group_importance()\n",
    "base = dw_ad.loc[\"base\",:]\n",
    "dw_ad = 100 * (base - dw_ad) / base\n",
    "for forecast in dw_ad.columns:\n",
    "    fore_df_ad = dw_ad.loc[:,forecast].copy()\n",
    "    fore_df_ad.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df_ad.iloc[:20].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance decrease\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these two approaches give the same answer? They shouldn't.. Why? Let's discuss.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is the worth of ${\\it potential}$ observations? what data should we collect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we are \"carrying\" cell-by-cell heads, reach-based sfr flows, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:53.232394Z",
     "iopub.status.busy": "2020-11-12T06:01:53.232394Z",
     "iopub.status.idle": "2020-11-12T06:01:53.248560Z",
     "shell.execute_reply": "2020-11-12T06:01:53.248560Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = sc.pst.observation_data\n",
    "potential_obs = obs.loc[obs.obsnme.apply(lambda x: x.startswith(\"hds_02\") and x.endswith(\"{0:03d}\".format(m.nper-1))),\"obsnme\"].tolist()\n",
    "nz_obs = set(pst.nnz_obs_names)\n",
    "potential_obs = [o for o in potential_obs if o not in nz_obs]  \n",
    "len(potential_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore repeat above analysis for the observations that currently have zero weight by turning those observations \"on\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beware: calculating the Schur complement for all potential observation types and locations could take some time!! So we will sample to speed things up. You may need to further reduce the number of potential obs - you can do this by adding [0::2] to take every second element for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:01:53.263535Z",
     "iopub.status.busy": "2020-11-12T06:01:53.263535Z",
     "iopub.status.idle": "2020-11-12T06:06:13.716722Z",
     "shell.execute_reply": "2020-11-12T06:06:13.716722Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "df_worth_new = sc.get_added_obs_importance(obslist_dict=potential_obs, base_obslist=sc.pst.nnz_obs_names, reset_zero_weight=True)\n",
    "print(\"took:\",datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:13.727110Z",
     "iopub.status.busy": "2020-11-12T06:06:13.727110Z",
     "iopub.status.idle": "2020-11-12T06:06:13.781824Z",
     "shell.execute_reply": "2020-11-12T06:06:13.781824Z"
    }
   },
   "outputs": [],
   "source": [
    "df_worth_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nice! now let's process a little bit and make some plots of (potential) data worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:13.802405Z",
     "iopub.status.busy": "2020-11-12T06:06:13.802405Z",
     "iopub.status.idle": "2020-11-12T06:06:13.824100Z",
     "shell.execute_reply": "2020-11-12T06:06:13.824100Z"
    }
   },
   "outputs": [],
   "source": [
    "def worth_plot_prep(df):\n",
    "    # some processing\n",
    "    df_new_base = df.loc[\"base\",:].copy()  # \"base\" row\n",
    "    df_new_imax = df.apply(lambda x: df_new_base - x, axis=1).idxmax()  # obs with largest unc red for each pred\n",
    "    df_new_worth = 100.0 * (df.apply(lambda x: df_new_base - x, axis=1) / df_new_base)  # normalizing like above\n",
    "    \n",
    "    # plot prep\n",
    "    df_new_worth_plot = df_new_worth[df_new_worth.index != 'base'].copy()\n",
    "    df_new_worth_plot.loc[:,'names'] = df_new_worth_plot.index\n",
    "    names = df_new_worth_plot.names\n",
    "    df_new_worth_plot.loc[:,\"i\"] = names.apply(lambda x: int(x[8:10]))\n",
    "    df_new_worth_plot.loc[:,\"j\"] = names.apply(lambda x: int(x[11:14]))\n",
    "    df_new_worth_plot.loc[:,'kper'] = names.apply(lambda x: int(x[-3:]))\n",
    "    #df_new_worth_plot.head()\n",
    "    \n",
    "    return df_new_worth_plot, df_new_imax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:13.895671Z",
     "iopub.status.busy": "2020-11-12T06:06:13.880046Z",
     "iopub.status.idle": "2020-11-12T06:06:14.050732Z",
     "shell.execute_reply": "2020-11-12T06:06:14.050732Z"
    }
   },
   "outputs": [],
   "source": [
    "df_worth_new_plot, df_worth_new_imax = worth_plot_prep(df_worth_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.060840Z",
     "iopub.status.busy": "2020-11-12T06:06:14.060840Z",
     "iopub.status.idle": "2020-11-12T06:06:14.068469Z",
     "shell.execute_reply": "2020-11-12T06:06:14.068469Z"
    }
   },
   "outputs": [],
   "source": [
    "df_worth_new_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.068469Z",
     "iopub.status.busy": "2020-11-12T06:06:14.068469Z",
     "iopub.status.idle": "2020-11-12T06:06:14.085411Z",
     "shell.execute_reply": "2020-11-12T06:06:14.085411Z"
    }
   },
   "outputs": [],
   "source": [
    "df_worth_new_imax  # which obs causes largest unc var reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.099309Z",
     "iopub.status.busy": "2020-11-12T06:06:14.099309Z",
     "iopub.status.idle": "2020-11-12T06:06:14.116902Z",
     "shell.execute_reply": "2020-11-12T06:06:14.116902Z"
    }
   },
   "outputs": [],
   "source": [
    "df_worth_new_plot.drop(axis=1,labels=[\"part_status\"],inplace=True) # drop \"part_status\"\n",
    "df_worth_new_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.131470Z",
     "iopub.status.busy": "2020-11-12T06:06:14.131470Z",
     "iopub.status.idle": "2020-11-12T06:06:14.147437Z",
     "shell.execute_reply": "2020-11-12T06:06:14.147437Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_added_importance(df_worth_plot, ml, forecast_name=None, \n",
    "                          newlox=None,):\n",
    "\n",
    "    vmax = df_worth_plot[forecast_name].max()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "    if newlox:\n",
    "        currx = []\n",
    "        curry = []\n",
    "        for i,clox in enumerate(newlox):\n",
    "            crow = int(clox[8:10])\n",
    "            ccol = int(clox[11:14])\n",
    "            currx.append(ml.sr.xcentergrid[crow,ccol])\n",
    "            curry.append(ml.sr.ycentergrid[crow,ccol])\n",
    "\n",
    "    sp = ml.nper - 1\n",
    "    unc_array = np.zeros_like(ml.upw.hk[0].array) - 1\n",
    "    df_worth_csp = df_worth_plot.groupby('kper').get_group(sp)\n",
    "    for i,j,unc in zip(df_worth_csp.i,df_worth_csp.j,\n",
    "                       df_worth_csp[forecast_name]):\n",
    "        unc_array[i,j] = unc \n",
    "    unc_array[unc_array == -1] = np.NaN\n",
    "    cb = ax.imshow(unc_array,interpolation=\"nearest\",\n",
    "                   alpha=0.5,extent=ml.sr.get_extent(), \n",
    "                   vmin=0, vmax=vmax)\n",
    "    \n",
    "    plt.colorbar(cb,label=\"percent uncertainty reduction\")\n",
    "\n",
    "    # plot sfr\n",
    "    sfr_data = ml.sfr.stress_period_data[0]\n",
    "    sfr_x = ml.sr.xcentergrid[sfr_data[\"i\"],sfr_data[\"j\"]]\n",
    "    sfr_y = ml.sr.ycentergrid[sfr_data[\"i\"],sfr_data[\"j\"]]\n",
    "    for (x,y) in zip(sfr_x,sfr_y):\n",
    "        ax.scatter([x],[y],marker=\"s\",color=\"g\",s=26)\n",
    "\n",
    "    # plot the pumping wells\n",
    "    wel_data = ml.wel.stress_period_data[0]\n",
    "    wel_x = ml.sr.xcentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "    wel_y = ml.sr.ycentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "    for w,(x,y) in enumerate(zip(wel_x,wel_y)):\n",
    "        ax.scatter([x],[y],marker=\"v\",color=\"m\",s=10)\n",
    "\n",
    "    if newlox:\n",
    "        for nl,(cx,cy,cobs) in enumerate(zip(currx, curry, newlox)):\n",
    "            #csp = int(cobs[-1])\n",
    "            #if csp == sp:\n",
    "            ax.plot(cx, cy, 'rd', mfc=None, ms=10, alpha=0.8)\n",
    "            ax.text(cx-50,cy-50, nl, size=10)\n",
    "\n",
    "    # plot the location of the forecast if possible\n",
    "    if forecast_name.startswith('hds'):\n",
    "        i = int(forecast_name[8:10])\n",
    "        j = int(forecast_name[11:14])\n",
    "        forecast_x = ml.sr.xcentergrid[i,j]\n",
    "        forecast_y = ml.sr.ycentergrid[i,j]\n",
    "        ax.scatter(forecast_x, forecast_y, marker='o', s=600, alpha=0.5)\n",
    "\n",
    "    ax.set_title(\"worth for {0}\\n at kper {1}\".format(forecast_name,sp), fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.147437Z",
     "iopub.status.busy": "2020-11-12T06:06:14.147437Z",
     "iopub.status.idle": "2020-11-12T06:06:14.163346Z",
     "shell.execute_reply": "2020-11-12T06:06:14.163346Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pst.forecast_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.178695Z",
     "iopub.status.busy": "2020-11-12T06:06:14.178695Z",
     "iopub.status.idle": "2020-11-12T06:06:14.518021Z",
     "shell.execute_reply": "2020-11-12T06:06:14.518021Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_added_importance(df_worth_plot=df_worth_new_plot, ml=m,forecast_name=\"fa_tw_20171001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:14.526171Z",
     "iopub.status.busy": "2020-11-12T06:06:14.526171Z",
     "iopub.status.idle": "2020-11-12T06:06:15.882636Z",
     "shell.execute_reply": "2020-11-12T06:06:15.882636Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in [x for x in forecasts if \"part_status\" not in x]:\n",
    "    fig = plot_added_importance(df_worth_plot=df_worth_new_plot, ml=m, \n",
    "                                forecast_name=i)\n",
    "    #fig.savefig('add_worth_{}.pdf'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the \"next best\" observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we would ultimately like to know... Takes into account what we already know through incrementally making additional observations. For example, consider making an observation in the middle of the zone of highest worth. Where should we subsequently collect data? \n",
    "\n",
    "Let's just use the same potential observation list for now (the head in every top-layer cell) and evaluate which ones to collect, if we only had the budget for 5, in the context of the particle travel time prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:15.882636Z",
     "iopub.status.busy": "2020-11-12T06:06:15.882636Z",
     "iopub.status.idle": "2020-11-12T06:06:15.900322Z",
     "shell.execute_reply": "2020-11-12T06:06:15.900322Z"
    }
   },
   "outputs": [],
   "source": [
    "obs.obgnme.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:15.929531Z",
     "iopub.status.busy": "2020-11-12T06:06:15.929531Z",
     "iopub.status.idle": "2020-11-12T06:06:15.947195Z",
     "shell.execute_reply": "2020-11-12T06:06:15.947195Z"
    }
   },
   "outputs": [],
   "source": [
    "new_obs = obs.loc[obs.obsnme.apply(lambda x: x.startswith(\"hds_00\") and x.endswith(\"{0:03d}\".format(m.nper-1))),\"obsnme\"]\n",
    "new_obs = new_obs.tolist()\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:15.947195Z",
     "iopub.status.busy": "2020-11-12T06:06:15.947195Z",
     "iopub.status.idle": "2020-11-12T06:06:15.979767Z",
     "shell.execute_reply": "2020-11-12T06:06:15.979767Z"
    }
   },
   "outputs": [],
   "source": [
    "pst.forecast_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:06:15.995561Z",
     "iopub.status.busy": "2020-11-12T06:06:15.995561Z",
     "iopub.status.idle": "2020-11-12T06:27:47.143387Z",
     "shell.execute_reply": "2020-11-12T06:27:47.143387Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "next_most_df = sc.next_most_important_added_obs(forecast='fa_tw_20171001',niter=5,obslist_dict=dict(zip(new_obs,new_obs)),\n",
    "                                                base_obslist=sc.pst.nnz_obs_names,reset_zero_weight=True)\n",
    "print(\"took:\",datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:47.153509Z",
     "iopub.status.busy": "2020-11-12T06:27:47.153509Z",
     "iopub.status.idle": "2020-11-12T06:27:47.163684Z",
     "shell.execute_reply": "2020-11-12T06:27:47.163684Z"
    }
   },
   "outputs": [],
   "source": [
    "next_most_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:47.178098Z",
     "iopub.status.busy": "2020-11-12T06:27:47.163684Z",
     "iopub.status.idle": "2020-11-12T06:27:47.591939Z",
     "shell.execute_reply": "2020-11-12T06:27:47.591939Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_added_importance(df_worth_new_plot, m, 'fa_tw_20171001', \n",
    "                            newlox=next_most_df.best_obs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: an important assumption underpinning the above is that the model is able to fit observations to a level that is commensurate with measurement noise... Are we comfortable with this assumption? We will discuss this more in `pestpp-glm_part2.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:47.607724Z",
     "iopub.status.busy": "2020-11-12T06:27:47.591939Z",
     "iopub.status.idle": "2020-11-12T06:27:47.625172Z",
     "shell.execute_reply": "2020-11-12T06:27:47.625172Z"
    }
   },
   "outputs": [],
   "source": [
    "# recall...\n",
    "pst.observation_data.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### an \"extra\" if we have time: parameter identifiability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:47.625172Z",
     "iopub.status.busy": "2020-11-12T06:27:47.625172Z",
     "iopub.status.idle": "2020-11-12T06:27:49.166125Z",
     "shell.execute_reply": "2020-11-12T06:27:49.166125Z"
    }
   },
   "outputs": [],
   "source": [
    "la = pyemu.ErrVar(jco=jco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:49.186891Z",
     "iopub.status.busy": "2020-11-12T06:27:49.186891Z",
     "iopub.status.idle": "2020-11-12T06:27:50.801428Z",
     "shell.execute_reply": "2020-11-12T06:27:50.799769Z"
    }
   },
   "outputs": [],
   "source": [
    "s = la.qhalfx.s  # singular spectrum\n",
    "s.x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:50.819559Z",
     "iopub.status.busy": "2020-11-12T06:27:50.811521Z",
     "iopub.status.idle": "2020-11-12T06:27:50.952423Z",
     "shell.execute_reply": "2020-11-12T06:27:50.952423Z"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.log10(s.x))\n",
    "ax.set_ylabel(\"log10 singular value\")\n",
    "ax.set_xlabel(\"index\")\n",
    "#ax.set_xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, singluar spectrum decays rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:50.960658Z",
     "iopub.status.busy": "2020-11-12T06:27:50.960658Z",
     "iopub.status.idle": "2020-11-12T06:27:50.978301Z",
     "shell.execute_reply": "2020-11-12T06:27:50.978301Z"
    }
   },
   "outputs": [],
   "source": [
    "truncation_thresh = 5e-5\n",
    "n_signif_singvals = ((s.x / s[0].x) > truncation_thresh).sum()\n",
    "n_signif_singvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:50.978301Z",
     "iopub.status.busy": "2020-11-12T06:27:50.978301Z",
     "iopub.status.idle": "2020-11-12T06:27:51.009553Z",
     "shell.execute_reply": "2020-11-12T06:27:51.009553Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This means that, on the basis of the {0} (non-zero) weighted observations, \\\n",
    "there are {1} unique pieces of information in the calibration dataset.  \\\n",
    "Recall the inverse problem we are trying to solve involves the estimation of {2} parameters using this information only...\".\\\n",
    "      format(la.pst.nnz_obs, n_signif_singvals, pst.npar_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the identifiability of actual model parameters based on these singular vectors. Identifiability ranges from 0 (not identified by the data) to 1 (full identified by the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:51.009553Z",
     "iopub.status.busy": "2020-11-12T06:27:51.009553Z",
     "iopub.status.idle": "2020-11-12T06:27:51.509260Z",
     "shell.execute_reply": "2020-11-12T06:27:51.509260Z"
    }
   },
   "outputs": [],
   "source": [
    "ident_df = la.get_identifiability_dataframe(4)  # sing val trunc defaults to pst.nnz_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:51.509260Z",
     "iopub.status.busy": "2020-11-12T06:27:51.509260Z",
     "iopub.status.idle": "2020-11-12T06:27:51.703106Z",
     "shell.execute_reply": "2020-11-12T06:27:51.703106Z"
    }
   },
   "outputs": [],
   "source": [
    "ident_df.sort_values(by=\"ident\",ascending=False).iloc[0:10].loc[:,\"ident\"].plot(kind=\"bar\",figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:51.708933Z",
     "iopub.status.busy": "2020-11-12T06:27:51.708933Z",
     "iopub.status.idle": "2020-11-12T06:27:52.018591Z",
     "shell.execute_reply": "2020-11-12T06:27:52.018591Z"
    }
   },
   "outputs": [],
   "source": [
    "id = pyemu.plot_utils.plot_id_bar(ident_df.sort_values(by=\"ident\",ascending=False).iloc[0:10], figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note similarity with some of the earlier parameter contribution to forecast uncertainty results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:52.018591Z",
     "iopub.status.busy": "2020-11-12T06:27:52.018591Z",
     "iopub.status.idle": "2020-11-12T06:27:52.193908Z",
     "shell.execute_reply": "2020-11-12T06:27:52.193908Z"
    }
   },
   "outputs": [],
   "source": [
    "css = la.get_par_css_dataframe()\n",
    "css.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:52.193908Z",
     "iopub.status.busy": "2020-11-12T06:27:52.193908Z",
     "iopub.status.idle": "2020-11-12T06:27:52.219364Z",
     "shell.execute_reply": "2020-11-12T06:27:52.217160Z"
    }
   },
   "outputs": [],
   "source": [
    "css = css.sort_values(by=\"pest_css\",ascending=False)\n",
    "css = css.loc[css.pest_css==0.0,:]\n",
    "len([p for p in css.index if \"sy\" in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T06:27:52.219364Z",
     "iopub.status.busy": "2020-11-12T06:27:52.219364Z",
     "iopub.status.idle": "2020-11-12T06:27:52.239963Z",
     "shell.execute_reply": "2020-11-12T06:27:52.239963Z"
    }
   },
   "outputs": [],
   "source": [
    "par = pst.parameter_data.loc[pst.adj_par_names]\n",
    "par.loc[par.parnme.apply(lambda x: \"sy\" in x),:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
