{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOSM - a brief overview (with equations!)\n",
    "\n",
    "## FOSM = \"First Order, Second Moment\", which is the mathematical description of what is being described\n",
    "\n",
    "## FOSM = \"linear uncertainty analysis\", page 460 in Anderson et al. (2015), PEST parlance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/bayes.png\" style=\"float: left; width: 25%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"figs/jacobi.jpg\" style=\"float: left; width: 25%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"figs/gauss.jpg\" style=\"float: left; width: 22%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"figs/schur.jpg\" style=\"float: left; width: 22%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<p style=\"clear: both;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\underbrace{P(\\boldsymbol{\\theta}|\\textbf{d})}_{\\substack{\\text{what we} \\\\ \\text{know now}}} \\propto \\underbrace{\\mathcal{L}(\\boldsymbol{\\theta} | \\textbf{d})}_{\\substack{\\text{what we} \\\\ \\text{learned}}} \\underbrace{P(\\boldsymbol{\\theta})}_{\\substack{\\text{what we} \\\\ \\text{knew}}} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## This in a nutshell is the famous Bayes Rule.\n",
    "\n",
    "### We can also think of this graphically, as taken from Anderson et al. (2015) in slightly different notation but the same equation and concept:\n",
    "\n",
    "<img src=\"figs/AW&H2015.png\" style=\"float: right\">\n",
    "\n",
    "<img src=\"figs/Fig10.3_Bayes_figure.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem is for real-world problems, the likelihood function  $\\mathcal{L}(\\theta | \\textbf{D})$ is high-dimensional and non-parameteric, requiring non-linear (typically Monte Carlo) integration for rigorous Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But, we can make some assumptions and greatly reduce computational burden. This is why we often suggest using these linear methods first before burning the silicon on the non-linear ones like Monte Carlo.  \n",
    "\n",
    "## How do we reduced the computational burden?  By using these shortcuts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.) an approximate linear relation between pars and obs  \n",
    "\n",
    "<img src=\"figs/jacobi.jpg\" style=\"float: left; width: 15%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "\n",
    "##     <center> $\\mathbf{J} \\approx \\text{constant}$, $\\frac{\\partial\\text{obs}}{\\partial\\text{par}} \\approx \\text{constant}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) The parameter and forecast prior and posterior distributions are approximately Gaussian\n",
    "\n",
    "<img src=\"figs/gauss.jpg\" style=\"float: left; width: 10%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "\n",
    "##  <center>  $ P(\\boldsymbol{\\theta}|\\mathbf{d}) \\approx \\mathcal{N}(\\overline{\\boldsymbol{\\mu}}_{\\boldsymbol{\\theta}},\\overline{\\boldsymbol{\\Sigma}}_{\\boldsymbol{\\theta}})$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armed with these two assumptions, from Bayes equations, one can derive the Schur complement for conditional uncertainty propogation:\n",
    "<img src=\"figs/schur.jpg\" style=\"float: left; width: 10%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "\n",
    "## <center> $\\underbrace{\\overline{\\boldsymbol{\\Sigma}}_{\\boldsymbol{\\theta}}}_{\\substack{\\text{what we} \\\\ \\text{know now}}} = \\underbrace{\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}}_{\\substack{\\text{what we} \\\\ \\text{knew}}} - \\underbrace{\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}\\bf{J}^T\\left[\\bf{J}\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}\\bf{J}^T + \\boldsymbol{\\Sigma}_{\\boldsymbol{\\epsilon}}\\right]^{-1}\\bf{J}\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}}_{\\text{what we learned}}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some remarks:\n",
    "## 0.) no parameter values or observation values\n",
    "## 1.) \"us + data\" = $\\overline{\\Sigma}_{\\theta}$; \"us\" = $\\Sigma_{\\theta}$\n",
    "## 2.) the '-' on the RHS shows that we are (hopefully) collapsing the probability manifold in parameter space by \"learning\" from the data. Or put another way, we are subtracting from the uncertainty we started with (we started with the Prior uncertainty)\n",
    "## 3.) uncertainty in our measurements of the world is encapsulated in $\\Sigma_{\\epsilon}$. If the \"observations\" are highly uncertain, then parameter \"learning\" decreases because $\\Sigma_{\\epsilon}$ is in the denominator. Put another way, if our measured data are made (assumed) to be accurate and precise, then uncertainty associated with the parameters that are constrained by these measured data is reduced - we \"learn\" more. \n",
    "## 4.) what quantities are needed? $\\bf{J}$, $\\boldsymbol{\\Sigma}_{\\theta}$, and $\\boldsymbol{\\Sigma}_{\\epsilon}$\n",
    "## 5.) the diagonal of $\\Sigma_{\\theta}$ and $\\overline{\\Sigma}_{\\theta}$ are the Prior and Posterior uncertainty (variance) of each adjustable parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But what about forecasts? We can use the same assumptions:\n",
    "<img src=\"figs/jacobi.jpg\" style=\"float: left; width: 15%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"figs/gauss.jpg\" style=\"float: left; width: 12%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<p style=\"clear: both;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prior forecast uncertainty (variance): $\\sigma^2_{s} = \\mathbf{y}^T\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}\\mathbf{y}$\n",
    "## posterior forecast uncertainty (variance): $\\overline{\\sigma}^2_{s} = \\mathbf{y}^T\\overline{\\boldsymbol{\\Sigma}}_{\\boldsymbol{\\theta}}\\mathbf{y}$\n",
    "## some remarks:\n",
    "\n",
    "## - no parameter values or forecast values\n",
    "## - what's needed? $\\bf{y}$, which is the *sensitivity of a given forecast* to each adjustable parameter. Each forecast will have its own $\\bf{y}$\n",
    "## -   How do I get $\\bf{y}$? the easiest way is to include your forecast(s) as an observation in the control file - then we get the $\\bf{y}$'s for free during the parameter estimation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics of calculating FOSM parameter and forecast uncertainty estimates\n",
    "\n",
    "### in the PEST world:\n",
    "<img src=\"figs/workflow.png\" style=\"float: left; width: 50%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in PEST++\n",
    "\n",
    "<img src=\"figs/workflow++.png\" style=\"float: left; width: 50%; margin-right: 1%; margin-bottom: 0.5em;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on:  Demystifying matrices and vectors used in FOSM\n",
    "\n",
    "Pages 461-465 of Anderson et al. use the PREDUNC equation of PEST to discuss an applied view of FOSM, what goes into it, and what it means in practice.  Here we will look more closely at these.  The objective is to get a better feel for what is going on under the hood in linear uncertainty analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:31.261185Z",
     "iopub.status.busy": "2020-11-13T06:26:31.260562Z",
     "iopub.status.idle": "2020-11-13T06:26:31.859749Z",
     "shell.execute_reply": "2020-11-13T06:26:31.860313Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"..\")\n",
    "import pyemu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's check out the files that pestpp-glm created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the parameter uncertainty summary written by pestpp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:31.864672Z",
     "iopub.status.busy": "2020-11-13T06:26:31.864203Z",
     "iopub.status.idle": "2020-11-13T06:26:31.882287Z",
     "shell.execute_reply": "2020-11-13T06:26:31.882773Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join('..','master_glm','freyberg_pp.par.usum.csv')):\n",
    "    df = pd.read_csv(os.path.join('..','master_glm','freyberg_pp.par.usum.csv'),index_col=0)\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join('pstfiles','freyberg_pp.par.usum.csv'),index_col=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:31.890955Z",
     "iopub.status.busy": "2020-11-13T06:26:31.890038Z",
     "iopub.status.idle": "2020-11-13T06:26:31.893149Z",
     "shell.execute_reply": "2020-11-13T06:26:31.893639Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['CONST_RECH14__CN'].to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:31.906700Z",
     "iopub.status.busy": "2020-11-13T06:26:31.906282Z",
     "iopub.status.idle": "2020-11-13T06:26:31.984548Z",
     "shell.execute_reply": "2020-11-13T06:26:31.984965Z"
    }
   },
   "outputs": [],
   "source": [
    "axes = pyemu.plot_utils.plot_summary_distributions(df.loc['WELFLUX_023'].to_frame().T,subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a similar file for forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:32.073515Z",
     "iopub.status.busy": "2020-11-13T06:26:32.042204Z",
     "iopub.status.idle": "2020-11-13T06:26:32.347574Z",
     "shell.execute_reply": "2020-11-13T06:26:32.348030Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join('..','master_glm','freyberg_pp.pred.usum.csv')):\n",
    "    axes = pyemu.plot_utils.plot_summary_distributions(os.path.join('..','master_glm','freyberg_pp.pred.usum.csv'),subplots=True)\n",
    "else:\n",
    "    axes = pyemu.plot_utils.plot_summary_distributions(os.path.join('pstfiles','freyberg_pp.pred.usum.csv'),subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So that's cool!  Questions:\n",
    "### - where do the prior parameter distro's come from?\n",
    "### - where do the prior forecast distro's come from?\n",
    "### - why are are the posterior distro's differenent than the priors?\n",
    "\n",
    "## but pyemu does the same calculations, but also allows you to do other, more exciting things..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOSM with pyEMU\n",
    "\n",
    "### The ``Schur`` object is one of the primary object for FOSM in pyEMU and the only one we will talk about in this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:32.351772Z",
     "iopub.status.busy": "2020-11-13T06:26:32.351262Z",
     "iopub.status.idle": "2020-11-13T06:26:33.506451Z",
     "shell.execute_reply": "2020-11-13T06:26:33.506965Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join('..','master_glm','freyberg_pp.jcb')):\n",
    "    sc = pyemu.Schur(os.path.join('..','master_glm','freyberg_pp.jcb'),verbose=True)\n",
    "else:\n",
    "    sc = pyemu.Schur(os.path.join('pstfiles','freyberg_pp.jcb'),verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that seemed too easy, right?  Well, underhood the ``Schur`` object found the control file (\"freyberg_zn.pst\") and used it to build the prior parameter covariance matrix, $\\boldsymbol{\\Sigma}_{\\theta}$, from the parameter bounds and the observation noise covariance matrix ($\\boldsymbol{\\Sigma}_{\\epsilon}$) from the observation weights.  These are the ``Schur.parcov`` and ``Schur.obscov`` attributes.  \n",
    "\n",
    "### The ``Schur`` object also found the \"++forecasts()\" optional pestpp argument in the control, found the associated rows in the Jacobian matrix file and extracted those rows to serve as forecast sensitivity vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.510049Z",
     "iopub.status.busy": "2020-11-13T06:26:33.509557Z",
     "iopub.status.idle": "2020-11-13T06:26:33.511717Z",
     "shell.execute_reply": "2020-11-13T06:26:33.512208Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pst.pestpp_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall that a Jacobian matrix looks at the changes in observations as a parameter is changed.  Therefore the Jacobian matrix has parameters in the columns and observations in the rows.  The bulk of the matrix is made up of the difference in  observations between a base run and a run where the parameter at the column head was perturbed (typically 1% from the base run value - controlled by the \"parameter groups\" info).  Now we'll plot out the Jacobian matrix from the fryberg_zones activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.515574Z",
     "iopub.status.busy": "2020-11-13T06:26:33.514817Z",
     "iopub.status.idle": "2020-11-13T06:26:33.535015Z",
     "shell.execute_reply": "2020-11-13T06:26:33.535539Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.jco.to_dataframe().loc[sc.pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This reports changes in observations to a change in a parameter.  We can report how  forecasts of interests change as the parameter is perturbed.  Note pyemu extracted the forecast rows from the Jacobian on instantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.543029Z",
     "iopub.status.busy": "2020-11-13T06:26:33.542541Z",
     "iopub.status.idle": "2020-11-13T06:26:33.544771Z",
     "shell.execute_reply": "2020-11-13T06:26:33.545194Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.forecasts.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each of these columns in a $\\bf{y}$ vector used in the FOSM calculations...that's it!\n",
    "\n",
    "\n",
    "### But the forecasts also have uncertainty because we have inherent uncertainty in the parameters.  Here's what we have defined for parameter uncertainty - the Prior.  It was constructed on-the-fly from the parameter bounds in the control file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.547407Z",
     "iopub.status.busy": "2020-11-13T06:26:33.547000Z",
     "iopub.status.idle": "2020-11-13T06:26:33.564121Z",
     "shell.execute_reply": "2020-11-13T06:26:33.564538Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.parcov.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 463-464 in Anderson et al. (2015) spends some time on what is shown above.  For our purposes, a diagonal Prior -  numbers only along the diagaonal - shows that we expect the uncertainty for each parameter to only results from itself - there is no covariance with other parameters. The numbers themselves reflect \"the innate parameter variability\", and is input into the maths as a standard deviation around the parameter value.  This is called the \"C(p) matrix of innate parameter variability\" in the PEST parlance.\n",
    "\n",
    "## IMPORTANT POINT:  Again, how did PEST++ and pyEMU get these standard deviations shown in the diagonal?  From the *parameter bounds* that were specified for each parameter in the PEST control file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On page 462-463 in Anderson et al. they also point out that a forecast uncertainty has to take into account the noise/uncertainty in the observations.   Similar to the parameter Prior - the $\\Sigma_{\\theta}$ matrix -, it is a covariance matrix of measurement error associated with the observations.  This is the same as  $\\Sigma_{\\epsilon}$ that we discussed above. For our Fryberg problem, say each observation had a standard devation of 1 around the observed value.  The $C{\\epsilon}$ matrix would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.621948Z",
     "iopub.status.busy": "2020-11-13T06:26:33.574963Z",
     "iopub.status.idle": "2020-11-13T06:26:33.624306Z",
     "shell.execute_reply": "2020-11-13T06:26:33.624856Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.obscov.to_dataframe().loc[sc.pst.nnz_obs_names,sc.pst.nnz_obs_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT POINT:  How did PEST++ and pyEMU get these standard deviations shown in the diagonal?  From the *weights* that were specified for each observation in the PEST control file.\n",
    "\n",
    "### IMPORTANT POINT: You can use FOSM in the \"pre-calibration\" state to design an objective function (e.g. weights) to maximize forecast uncertainty reduction.\n",
    "\n",
    "### IMPORTANT POINT: In PEST++, if a given observation has a larger-than-expected residual, the variance of said observation is reset to the variance implied by the residual.  That is, the diagonal elements of $\\Sigma_{\\epsilon}$ are reset according to the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, enough emphasis.  Here's the point.  When we apply FOSM using these matrices above we can see how our uncertainty changes during calibration, first for parameters and then for forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.628801Z",
     "iopub.status.busy": "2020-11-13T06:26:33.628326Z",
     "iopub.status.idle": "2020-11-13T06:26:33.907165Z",
     "shell.execute_reply": "2020-11-13T06:26:33.907657Z"
    }
   },
   "outputs": [],
   "source": [
    "df = sc.get_parameter_summary()\n",
    "df.sort_values(ascending=False, by='percent_reduction').iloc[:20].percent_reduction.plot(kind=\"bar\", figsize=(14,4))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do these results make sense?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Where did the \"prior_var\" and \"post_var\" columns come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T06:26:33.911446Z",
     "iopub.status.busy": "2020-11-13T06:26:33.910168Z",
     "iopub.status.idle": "2020-11-13T06:26:33.919189Z",
     "shell.execute_reply": "2020-11-13T06:26:33.919783Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.get_forecast_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Do these results make sense?  Remember, these are not the \"calibrated\" forecast values, these are the prior (before calibration) and posterior (after calibration) forecast uncertainties..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
