{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyEMU basics\n",
    "\n",
    "In this exercise, we will explore some of the capabilities of pyemu to deal with the PEST file formats, such as .pst, .jco/.jcb, .unc, .cov, .mat, etc, as well as generating PEST interface elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.__path__  # check that we're pointing to the provided snapshot of pyemu (and flopy) repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some pre-cooked files in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_d = \"handling_files\"\n",
    "\n",
    "os.listdir(f_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control files and the `Pst` class\n",
    "\n",
    "pyEMU encapsulates the PEST control file in the `Pst` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(f_d,\"freyberg_pp.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"*\" sections of the control file are stored as attributes of the `Pst` instance (the PEST variable names are used for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control data is handled by a special class that tries to prevent stupidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.formatted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = \"junk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEST++ options are stored in a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"lambdas\"].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a control file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(f_d,\"test.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preview of things to come..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(f_d,\"test.pst\"),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"handling_files/test.pst\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a control file from template and instruction files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: get a new control file from a template file (or files) and an instruction file (or files).  You can use the files in the `f_d` directory, from the GWV excersize, or you can write your own.  Change par bounds and obs weights then write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(f_d) if f[-3:] in [\"tpl\",\"ins\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.helpers.parse_dir_for_io_files(f_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "tpl_files = [os.path.join(f_d,\"freyberg.rch.tpl\")]\n",
    "in_files = [\"freyberg.rch\"]\n",
    "ins_files = [os.path.join(f_d,\"freyberg.travel.ins\")]\n",
    "out_files = [\"freyberg.travel\"]\n",
    "new_pst = pyemu.Pst.from_io_files(tpl_files=tpl_files,in_files=in_files,\n",
    "                                  ins_files=ins_files,out_files=out_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pst.write(os.path.join(f_d,\"test2.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pst.observation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pst.add_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyEMU implements a labeled matrix class and overloads the standard operators to make linear alg easier.  Let's start with covariance matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pyemu.Cov.from_parameter_data(pst)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.row_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.col_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.isdiagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `Cov` has some nice build-in methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.s #singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.v #right singular vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual array of values in the `.x` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.x[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your understandig: Why is the `x` attribute 1-D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cov.as_2d\n",
    "x[x==0] = np.NaN\n",
    "c = plt.imshow(x)\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_cov = pyemu.Cov.from_ascii(os.path.join(f_d,\"freyberg_pp.post.cov\"))\n",
    "post_cov.isdiagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = post_cov.as_2d\n",
    "x[x==0] = np.NaN\n",
    "c = plt.imshow(x)\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = post_cov.to_dataframe()\n",
    "rsum = df.sum(axis=1).sort_values()\n",
    "rsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: plot the singular spectrum of the posterior covariance matrix.  Then convert the posterior covariance matrix to correlation matrix, mask the diagonal and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint: Cov.to_pearson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual handling\n",
    "\n",
    "The `Pst` class tries load a residuals file in the constructor.  If that file is found, you can access some pretty cool stuff (you can pass the name of a residual file to the `Pst` constructor...).  The `res` attribute is stored as a `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrepancy based weight adjustment\n",
    "\n",
    "In a perfect (model and algorithm) world, we would acheive a final objective function that is equal to the number of (non-zero weighted) observations. But because of model error and simplifying assumptions in the algorithms we use for history matching, this is rarely the case.  More often, the final objective function is much larger than the number of observations.  This implies that we were not able to \"fit\" as well as we thought we could (were \"thought\" is incapsulated in the weights in the control file).  This really matters when we do posterior uncertainty analyses following a PEST run - we will see this again in the FOSM and data-worth notebooks. Note: dont make this adjustment until after you are through with history matching!!!\n",
    "\n",
    "The simpliest way to try to rectify this situation is to adjust the weights in the control file so that the resulting contribution to the objective function from each observation (or optional observation group) is equal 1 (or the number of members of the group).  This is related to Morozov's discrepancy principal (google it!).  `pyEMU` has a built in routine to help with this: `Pst.adjust_weights_discrepancy()` - great name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a copy of the contol file so we dont goof up later activities with the original\n",
    "pst2 = pyemu.Pst(os.path.join(f_d,\"freyberg_pp.pst\"))\n",
    "obs = pst2.observation_data\n",
    "fig,axes = plt.subplots(2,1,figsize=(10,10))\n",
    "pst2.observation_data.loc[pst2.nnz_obs_names,\"weight\"].plot(kind=\"bar\",ax=axes[0])\n",
    "pst2.res.loc[pst2.nnz_obs_names,:].apply(lambda x: (x.residual * obs.loc[x.name,\"weight\"])**2,axis=1).plot(kind=\"bar\",ax=axes[1])\n",
    "axes[0].set_title(\"original weights\")\n",
    "axes[1].set_title(\"original contribution to objective function\")\n",
    "axes[0].set_xticklabels([])\n",
    "print(\"original phi:\",pst2.phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see the objective function is much larger than the number of observations and the contribution to phi varies substantially across the observations...\n",
    "\n",
    "Now for the weight adjustment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst2.adjust_weights_discrepancy()\n",
    "obs = pst2.observation_data\n",
    "fig,axes = plt.subplots(2,1,figsize=(10,10))\n",
    "pst2.observation_data.loc[pst2.nnz_obs_names,\"weight\"].plot(kind=\"bar\",ax=axes[0])\n",
    "pst2.res.loc[pst2.nnz_obs_names,:].apply(lambda x: (x.residual * obs.loc[x.name,\"weight\"])**2,axis=1).plot(kind=\"bar\",ax=axes[1])\n",
    "axes[0].set_title(\"adjusted weights\")\n",
    "axes[1].set_title(\"adjusted contribution to objective function\")\n",
    "axes[0].set_xticklabels([])\n",
    "print(\"adjusted phi:\",pst2.phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the max contribution to phi from any observaton is 1.0.  the reason some of them are less than 1.0 is because we did not want to turn the weights up for the observations that are being matched well (so we keep the weights the same or decrease only, we dont want to increase the weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: plot a bar chart of residuals for non-zero weighted obs\n",
    "\n",
    "You can use the adjusted weight instance (`pst2`) or the original `pst`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Jacobian matrix\n",
    "\n",
    "A dervied pyemu.Matrix type..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jco = pyemu.Jco.from_binary(os.path.join(f_d,\"freyberg_pp.jcb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jco.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: form the normal matrix (`XtQX`) with non-zero weight obs and plot (`X` is the jacobian is `Q` is the inverse of the observation noise covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint Cov.from_observation_data()\n",
    "obscov = pyemu.Cov.from_observation_data(pst)\n",
    "Q = obscov.inv\n",
    "xtqx = jco.T * Q * jco\n",
    "x = xtqx.x\n",
    "plt.imshow(x,vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now invert XtQX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some sweet potting sugar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"phi_pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: Adjust the weights so that both non-zero obs groups contribute equally to the objective function (and plot!) - no model runs required..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: pst.adjust_weights\n",
    "print(pst.nnz_obs_groups)\n",
    "obsgrp_dict = {\"calhead\":100,\"calflux\":100}\n",
    "pst.adjust_weights(obsgrp_dict=obsgrp_dict)\n",
    "pst.plot(kind=\"phi_pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geostats in pyemu\n",
    "\n",
    "These are pure python so they arent super fast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_contribution = 1.0 # variance\n",
    "v_range = 1000\n",
    "exp_vario = pyemu.geostats.ExpVario(v_contribution,v_range)\n",
    "exp_vario.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets build a covariance matrix from x-y points.  We can generate these randomly or just use the pilot points template file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(f_d,\"hkpp.dat.tpl\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pyemu.geostats.ExpVario(0.1,5000).covariance_matrix(df.x,df.y,df.name).x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will just use a 1-D sequence to get a cov matrix (think \"time series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(0,365,1)\n",
    "y = np.ones_like(times)\n",
    "names = [\"t_\"+str(t) for t in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_contribution = 1.0 # variance\n",
    "v_range = 5 # days\n",
    "exp_vario = pyemu.geostats.ExpVario(v_contribution,v_range)\n",
    "exp_vario.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = exp_vario.covariance_matrix(times,y,names)\n",
    "plt.imshow(cov.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "The pyemu ensemble class inherit from pandas DataFrame so all that nice stuff is included for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pyemu.ParameterEnsemble.from_gaussian_draw(pst=pst,cov=pyemu.Cov.from_parameter_data(pst),num_reals=1000)\n",
    "pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your understanding: where did the first (mean vector) and second (covariance matrix) moments come from in that ensemble generation?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.iloc[:,0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.iloc[:,0].apply(np.log10).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was really easy...but what if we want to express spatial/temporal correlation in the prior?  that means we need to form mixed block-diagonal/diagonal cov matrix and then draw from it. In this case, we have spatially correlated pilot point parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(f_d,\"hkpp.dat.tpl\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a combined, block diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,1000)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "cov = pyemu.helpers.geostatistical_prior_builder(pst=pst,struct_dict={gs:df})\n",
    "x = cov.x.copy()\n",
    "x[x<1.0e-3] = np.NaN\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly the same line as above except here the `cov` includes some off-diagonals for the pilot points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pyemu.ParameterEnsemble.from_gaussian_draw(pst=pst,cov=cov,num_reals=10000)\n",
    "pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the values of the pilot points in space to see their correlation (or lack thereof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.parnme\n",
    "df.loc[:,\"parval1\"] = pe.loc[0,df.parnme].values\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(111,aspect=\"equal\")\n",
    "plt.scatter(df.x,df.y,c=df.parval1,s=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can \"kind of\" see that correlation, but if we krige these values to the model grid, we can really see it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"parval1\"] = pe.loc[0,df.parnme]\n",
    "df.index = np.arange(df.shape[0])\n",
    "arr = pyemu.geostats.fac2real(df,factors_file=os.path.join(f_d,\"hkpp.dat.fac\"),out_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log10(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: experiment with changing the variogram range and seeing how it changes the resulting parameter fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORESHADOWING: we can also form an empirical covariance matrix from this par ensemble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cov = pe.covariance_matrix()\n",
    "x = emp_cov.x.copy()\n",
    "x[x<1.0e-3] = np.NaN\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral simulation\n",
    "\n",
    "Because pyemu is pure python (and because the developers are lazy), it only implments spectral simulation for grid-scale field generation.  For regular grids without anisotropy and without conditioning data (\"known\" property values), it is identical to sequential gaussian sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,1)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,5)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,500)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
