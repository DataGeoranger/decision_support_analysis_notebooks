{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the PEST(++) interface around the enhanced Freyberg model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will construct a complex model independent (non-intrusive) interface around an existing `MODFLOW-NWT` model using the `python/flopy/pyemu` stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:56.788873Z",
     "iopub.status.busy": "2020-11-13T03:03:56.788125Z",
     "iopub.status.idle": "2020-11-13T03:03:57.332716Z",
     "shell.execute_reply": "2020-11-13T03:03:57.333224Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import pyemu\n",
    "import prep_deps\n",
    "import redis\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "%matplotlib inline\n",
    "pyemu.__path__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a base directory `b_d` from which we will read in a model already created `freyberg.nam`. This will form the basis of the remainder of the exercise (and those to follow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.336629Z",
     "iopub.status.busy": "2020-11-13T03:03:57.336131Z",
     "iopub.status.idle": "2020-11-13T03:03:57.338273Z",
     "shell.execute_reply": "2020-11-13T03:03:57.338764Z"
    }
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.341406Z",
     "iopub.status.busy": "2020-11-13T03:03:57.340954Z",
     "iopub.status.idle": "2020-11-13T03:03:57.342407Z",
     "shell.execute_reply": "2020-11-13T03:03:57.342855Z"
    }
   },
   "outputs": [],
   "source": [
    "b_d = os.path.join(\"temp_history\")\n",
    "nam_file = \"freyberg.nam\"\n",
    "assert os.path.exists(b_d),\"you need to run the setup_transient_history notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the existing Freyberg model. This version should run but is not yet connected with `PEST++`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.345243Z",
     "iopub.status.busy": "2020-11-13T03:03:57.344824Z",
     "iopub.status.idle": "2020-11-13T03:03:57.390449Z",
     "shell.execute_reply": "2020-11-13T03:03:57.390743Z"
    }
   },
   "outputs": [],
   "source": [
    "# note that to load a model in a different folder, you supply the namefile without path and supply the path\n",
    "# to it in the model_ws variable\n",
    "m = flopy.modflow.Modflow.load(nam_file,model_ws=b_d,check=False,forgive=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.404096Z",
     "iopub.status.busy": "2020-11-13T03:03:57.403674Z",
     "iopub.status.idle": "2020-11-13T03:03:57.549980Z",
     "shell.execute_reply": "2020-11-13T03:03:57.549401Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot some model attributes\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = plt.subplot(111,aspect=\"equal\")\n",
    "mm = flopy.plot.PlotMapView(model=m)\n",
    "mm.plot_grid()\n",
    "mm.plot_ibound()\n",
    "mm.plot_bc('SFR')\n",
    "mm.plot_bc(\"GHB\")\n",
    "ax = mm.ax\n",
    "#m.wel.stress_period_data.plot(ax=ax,mflay=2)\n",
    "\n",
    "# plot obs locations\n",
    "obs = pd.read_csv(os.path.join(\"..\",\"base_model_files\",\"obs_loc.csv\"))\n",
    "                  \n",
    "obs_x = [m.sr.xcentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "obs_y = [m.sr.ycentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "ax.scatter(obs_x,obs_y,marker='.',label=\"water-level obs\",s=80)\n",
    "\n",
    "#plot names on the pumping well locations\n",
    "wel_data = m.wel.stress_period_data[0]\n",
    "wel_x = m.sr.xcentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "wel_y = m.sr.ycentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "for i,(x,y) in enumerate(zip(wel_x,wel_y)):\n",
    "    ax.scatter([x],[y],color=\"red\",marker=\"s\",s=50)\n",
    "    #ax.text(x,y,\"{0}\".format(i+1),ha=\"center\",va=\"center\")\n",
    "\n",
    "ax.set_ylabel(\"y(m)\")\n",
    "ax.set_xlabel(\"x(m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can do a couple `flopy` things to move where the new model will be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.552680Z",
     "iopub.status.busy": "2020-11-13T03:03:57.552276Z",
     "iopub.status.idle": "2020-11-13T03:03:57.926343Z",
     "shell.execute_reply": "2020-11-13T03:03:57.926846Z"
    }
   },
   "outputs": [],
   "source": [
    "# assign the executable name for the model\n",
    "m.exe_name = \"mfnwt\"\n",
    "\n",
    "# now let's run this in a new folder called temp so we don't overwrite the original data\n",
    "m.change_model_ws(\"temp\",reset_external=True)\n",
    "\n",
    "# this writes all the MODFLOW files in the new location \n",
    "m.write_input()\n",
    "\n",
    "# the following helps get the dependecies (both python and executables) in the right place\n",
    "prep_deps.prep_template(t_d=\"temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can run the model once using a `pyemu` helper\n",
    "This helper is particularly useful if you run on more than one platform (e.g. Mac and Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:57.929812Z",
     "iopub.status.busy": "2020-11-13T03:03:57.929342Z",
     "iopub.status.idle": "2020-11-13T03:03:58.213789Z",
     "shell.execute_reply": "2020-11-13T03:03:58.214224Z"
    }
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"{0} {1}\".format(m.exe_name,m.name+\".nam\"),cwd=m.model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in the heads and plot them up along with the budget components\n",
    "Note that there is a historic period and a scenario with future conditions that differ. \n",
    "\n",
    "_For the future scenario, a serious drought, recharge is lower and pumping/abstraction is increased to make up for the presumed deficite in water for agriculture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:58.218861Z",
     "iopub.status.busy": "2020-11-13T03:03:58.218426Z",
     "iopub.status.idle": "2020-11-13T03:03:59.902411Z",
     "shell.execute_reply": "2020-11-13T03:03:59.902858Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=12\n",
    "plt.figure()\n",
    "hds = flopy.utils.HeadFile(os.path.join(m.model_ws,m.name+\".hds\"),model=m)\n",
    "hds.plot(mflay=0)\n",
    "lst = flopy.utils.MfListBudget(os.path.join(m.model_ws,m.name+\".list\"))\n",
    "df = lst.get_dataframes(diff=True)[0]\n",
    "plt.figure()\n",
    "ax = df.plot(kind=\"bar\",figsize=(30,30), grid=True,subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot depth to water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:03:59.915107Z",
     "iopub.status.busy": "2020-11-13T03:03:59.914694Z",
     "iopub.status.idle": "2020-11-13T03:04:00.027573Z",
     "shell.execute_reply": "2020-11-13T03:04:00.028001Z"
    }
   },
   "outputs": [],
   "source": [
    "dtw = m.dis.top.array - hds.get_data()[0,:,:]\n",
    "dtw = np.ma.masked_where(m.bas6.ibound[0].array==0,dtw)\n",
    "c = plt.imshow(dtw)\n",
    "plt.title('Depth to Water')\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the river and well locations expressed in the depth to water pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data structures related to what we want to parameterize and what we want to observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First the parameterization of model inputs. There is a method to the madness. Starting with MODFLOW parameters that are array-style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use package/parameter definitions with strings like `'pak.prop'` where `pak` is the abbreviation for a MODFLOW package as interpreted by `flopy` and `prop` is the short abbrevation for a property in the package. For example, `'upw.ss.'` is the specific storage in the Upstream Weighting Package.\n",
    "\n",
    "For parameters that vary by layer but not by time, we also need to specify which layer (zero-indexed....it's python y'all!) to apply to. So, specify the package/layer combo in a little list like:  \n",
    " `['upw.hk', 0]` for `hk` in the `upw` package in layer 0\n",
    "\n",
    "For parameters that vary by time but not by layer (basically talking recharge here), similar logic is used, except the counter indicates the stress period (still zero-based. still python) like:\n",
    "`['rch.rech',1]`  is recharge in stress period 1\n",
    "There is a shortcut for the numbering if you want to specify for all stress periods or all layers (as appropriate). Note that this will apply one set of parameters across layers or stress periods...it will not make distinct parameters for each. Rather than specifying a number, you use the variable `None` like:\n",
    "`['rch.rech',None]` for recharge across all stress periods or `['upw.ss',None]` for specific storage across all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are going to do this for a variety of packages/properties in two lists. One `props` will be for packages we want to apply distributed parameters to (e.g. pilot points and grid-based parameters). Then we will add another `constant_props` which will include stress-period based recharge multipliers as well. These will add together as we will see later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.031514Z",
     "iopub.status.busy": "2020-11-13T03:04:00.031014Z",
     "iopub.status.idle": "2020-11-13T03:04:00.034449Z",
     "shell.execute_reply": "2020-11-13T03:04:00.033911Z"
    }
   },
   "outputs": [],
   "source": [
    "props = []\n",
    "# here we specify which packages we wish to parameterize, \n",
    "# starting with those that do not change over time\n",
    "paks = [\"upw.hk\",\"upw.vka\",\"upw.ss\",\"upw.sy\",\"extra.prsity\"]  #\"extra\" because not a modflow parameter\n",
    "for k in range(m.nlay):\n",
    "    props.extend([[p,k] for p in paks])\n",
    "const_props = props.copy()\n",
    "props.append([\"rch.rech\",None])\n",
    "for kper in range(m.nper):\n",
    "    const_props.append([\"rch.rech\",kper])\n",
    "print('props')\n",
    "props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.037914Z",
     "iopub.status.busy": "2020-11-13T03:04:00.037441Z",
     "iopub.status.idle": "2020-11-13T03:04:00.039791Z",
     "shell.execute_reply": "2020-11-13T03:04:00.040282Z"
    }
   },
   "outputs": [],
   "source": [
    "print('const_props')\n",
    "const_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can handle MDOFLOW list-style parameters in two ways\n",
    "for `spatial_list_props` this will apply a multiplier distributed spatially that applied in all stress periods throughout the model\n",
    "\n",
    "for `temporal_list_props` this will apply a multiplier for each stress period applied to all the spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.043829Z",
     "iopub.status.busy": "2020-11-13T03:04:00.043391Z",
     "iopub.status.idle": "2020-11-13T03:04:00.045839Z",
     "shell.execute_reply": "2020-11-13T03:04:00.045427Z"
    }
   },
   "outputs": [],
   "source": [
    "spatial_list_props = [[\"wel.flux\",2],[\"ghb.cond\",0],[\"ghb.cond\",1],[\"ghb.cond\",2]]  # spatially by each list entry, across all stress periods\n",
    "temporal_list_props = [[\"wel.flux\",kper] for kper in range(m.nper)]  # spatially uniform for each stress period\n",
    "print(spatial_list_props)\n",
    "temporal_list_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we want to set up the extraction of model outputs that are of interest, not just places where we have state observations. In many cases we are interested in dry conditions and also the last stress period.  So lets include simulated water levels from a dry stress period and from the last stress period.  The container `hds_kperk` is a nested list of stress period and layer pairs from which we want to `observe` (in the PEST control file sense) the simulated water levels from (all active cells are included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.049140Z",
     "iopub.status.busy": "2020-11-13T03:04:00.048546Z",
     "iopub.status.idle": "2020-11-13T03:04:00.050939Z",
     "shell.execute_reply": "2020-11-13T03:04:00.050416Z"
    }
   },
   "outputs": [],
   "source": [
    "dry_kper = int(m.nper * 0.85) # the \"dry\" season in the last annual cycle\n",
    "hds_kperk = [[kper,k] for k in range(m.nlay) for kper in [0,dry_kper,m.nper-1]]\n",
    "#hds_kperk.extend([[1,k] for k in range(m.nlay)])\n",
    "hds_kperk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we setup monitoring of the SFR ASCII outputs.  \n",
    "we will accumulate the first 20 reaches and last 20 reaches (corresponding to the top and bottom half of the model, respectively) together to form forecasts of sw-gw exchange in the headwaters (`hw`) and tailwaters (`tw`).  We will also include the most downstream reach since that is where we have surface-water flow state observations for history matching.  The container `sft_obs_dict` will help us setup PEST `observations`.  Then later we will have to assign actual observation data to these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.053698Z",
     "iopub.status.busy": "2020-11-13T03:04:00.053288Z",
     "iopub.status.idle": "2020-11-13T03:04:00.054546Z",
     "shell.execute_reply": "2020-11-13T03:04:00.054965Z"
    }
   },
   "outputs": [],
   "source": [
    "sfr_obs_dict = {}\n",
    "sfr_obs_dict[\"hw\"] = np.arange(1,int(m.nrow/2))\n",
    "sfr_obs_dict[\"tw\"] = np.arange(int(m.nrow/2),m.nrow)\n",
    "sfr_obs_dict[\"gage_1\"] = [39]\n",
    "#for i in range(m.nrow):\n",
    "#    sfr_obs_dict[i] = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we go...\n",
    "\n",
    "This `pyemu` class has grown into a monster...it does (among other things):\n",
    "- sets up combinations of multiplier parameters for array inputs, including uniform, zones, pilot points, grids, and KL expansion types\n",
    "- sets up combinations of multiplier parameters for list inputs\n",
    "- handles several of the shitty modflow exceptions to the array and list style inputs\n",
    "- sets up large numbers of observations based on arrays or time series\n",
    "- writes .tpl, .ins, .pst, etc\n",
    "- writes a python forward run script\n",
    "- writes a prior parameter covaraince matrix using geostatistical correlations\n",
    "- draws from the prior parameter covariance matrix to generate a prior parameter ensemble\n",
    "\n",
    "WAT?!\n",
    "\n",
    "This will be slow because the pure python kriging...but, hey, its free!\n",
    "\n",
    "For our purposes, we will setup combinations of constant (by layer), pilot points and grid-scale parameters for each of the array-based properties we defined earlier.  This lets us explore options for parameterization and also start to understand how information flows in the history matching problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:00.058043Z",
     "iopub.status.busy": "2020-11-13T03:04:00.057634Z",
     "iopub.status.idle": "2020-11-13T03:04:15.671958Z",
     "shell.execute_reply": "2020-11-13T03:04:15.672503Z"
    }
   },
   "outputs": [],
   "source": [
    "pst_helper = pyemu.helpers.PstFromFlopyModel(nam_file,new_model_ws=\"template_history\",org_model_ws=\"temp\",\n",
    "                                             const_props=const_props,\n",
    "                                             spatial_list_props=spatial_list_props,\n",
    "                                             temporal_list_props=temporal_list_props,\n",
    "                                             remove_existing=True,\n",
    "                                             pp_props=props,\n",
    "                                             grid_props=props,\n",
    "                                             sfr_pars=[\"strk\"],\n",
    "                                             hds_kperk=hds_kperk,\n",
    "                                             sfr_obs=sfr_obs_dict,\n",
    "                                             build_prior=False,\n",
    "                                             model_exe_name=\"mfnwt\",\n",
    "                                             pp_space=4)\n",
    "prep_deps.prep_template(t_d=pst_helper.new_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to inspect the `template_history` directory that was just created in the same directory where this notebook is running.  You should find a pest control file names `freyberg.pst`, heaps of PEST-style template and instruction files and a python script named `forward_run.py`.  Let's checkout this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.677046Z",
     "iopub.status.busy": "2020-11-13T03:04:15.676553Z",
     "iopub.status.idle": "2020-11-13T03:04:15.679677Z",
     "shell.execute_reply": "2020-11-13T03:04:15.679129Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(i.rstrip()) for i in open('template_history/forward_run.py','r').readlines()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that `pst_helper` instance wrote this python script - WAT?!  Each time one of the PEST++ tools \"runs the model\", it will call this script, which will handle the required pre-processing to construct MODFLOW input files, run MODFLOW, and post-process the MODFLOW output files into files that PEST can read (with the instruction files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the `pst_helper` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pst_helper` instance contains the `pyemu.Pst` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.686293Z",
     "iopub.status.busy": "2020-11-13T03:04:15.685418Z",
     "iopub.status.idle": "2020-11-13T03:04:15.688128Z",
     "shell.execute_reply": "2020-11-13T03:04:15.688682Z"
    }
   },
   "outputs": [],
   "source": [
    "# so, pull out the `pyemu.Pst` instance which \n",
    "#contains all the input that ultimately goes in the PEST control %%file\n",
    "pst = pst_helper.pst\n",
    "pst.npar,pst.nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oh snap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyemu` uses `pandas` data frame format for the parameter and observation data sections. This offers plenty of querying and bulk editing options.\n",
    "\n",
    "Let's stop for a moment to get a better feel for what just happened! Let's dig in.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.705893Z",
     "iopub.status.busy": "2020-11-13T03:04:15.705294Z",
     "iopub.status.idle": "2020-11-13T03:04:15.713240Z",
     "shell.execute_reply": "2020-11-13T03:04:15.713741Z"
    }
   },
   "outputs": [],
   "source": [
    "# check out hydraulic conductivity parameters\n",
    "pst.parameter_data.loc[pst.parameter_data.parnme.str.contains('hk'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.722522Z",
     "iopub.status.busy": "2020-11-13T03:04:15.716916Z",
     "iopub.status.idle": "2020-11-13T03:04:15.724993Z",
     "shell.execute_reply": "2020-11-13T03:04:15.725532Z"
    }
   },
   "outputs": [],
   "source": [
    "# what about observations? in particular, the sfr flow-out observations?\n",
    "pst.observation_data.loc[pst.observation_data.obgnme.apply(lambda x: \"flout\" in x),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we have flow-out `observations` (in the PEST sense) for \"gage_1\", tailwaters (\"tw\") and headwaters (\"hw\"). Let's give these observations more meaningful group names (the `obgnme` attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.733204Z",
     "iopub.status.busy": "2020-11-13T03:04:15.732531Z",
     "iopub.status.idle": "2020-11-13T03:04:15.735274Z",
     "shell.execute_reply": "2020-11-13T03:04:15.736245Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "flout_obs = obs.loc[obs.obgnme.apply(lambda x: \"flout\" in x),\"obsnme\"]\n",
    "obs.loc[flout_obs,\"obgnme\"] = flout_obs.apply(lambda x: \"_\".join(x.split('_')[:-1]))\n",
    "obs.loc[flout_obs,\"obgnme\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time-series based observations\n",
    "\n",
    "We need to track specific head locations across all times for transient state observations that have been \"measured\".  To setup the tracking, we need to know where (lay-row-col) the observations are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.748760Z",
     "iopub.status.busy": "2020-11-13T03:04:15.748280Z",
     "iopub.status.idle": "2020-11-13T03:04:15.750538Z",
     "shell.execute_reply": "2020-11-13T03:04:15.750070Z"
    }
   },
   "outputs": [],
   "source": [
    "obs_locs = pd.read_csv(os.path.join(\"..\",\"base_model_files\",\"obs_loc.csv\"))\n",
    "#build obs names that correspond to the obsnme values in the control file\n",
    "obs_locs.loc[:,\"site\"] = obs_locs.apply(lambda x: \"trgw_{0:03d}_{1:03d}\".format(x.row-1,x.col-1),axis=1)\n",
    "kij_dict = {site:(2,r-1,c-1) for site,r,c in zip(obs_locs.site,obs_locs.row,obs_locs.col)}\n",
    "obs_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.753565Z",
     "iopub.status.busy": "2020-11-13T03:04:15.753106Z",
     "iopub.status.idle": "2020-11-13T03:04:15.754895Z",
     "shell.execute_reply": "2020-11-13T03:04:15.755330Z"
    }
   },
   "outputs": [],
   "source": [
    "kij_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `pyemu` groundwater utility to setup the transient groundwater level monitoring for us.  We need that location dictionary from above and the name of the binary file to process (the MODFLOW \"head save\" file).  Important: only run this code block once!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.758138Z",
     "iopub.status.busy": "2020-11-13T03:04:15.757694Z",
     "iopub.status.idle": "2020-11-13T03:04:15.832184Z",
     "shell.execute_reply": "2020-11-13T03:04:15.832613Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_file = os.path.join(pst_helper.m.model_ws,nam_file.replace(\".nam\",\".hds\"))\n",
    "frun_line,tr_hds_df = pyemu.gw_utils.setup_hds_timeseries(binary_file,kij_dict=kij_dict,include_path=True,model=pst_helper.m)\n",
    "pst_helper.frun_post_lines.append(frun_line)\n",
    "print(frun_line.strip());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the `frun_line` is in fact a valid line of python code - we added it to the `pst_helper` container for post-processing forward-run script lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.836229Z",
     "iopub.status.busy": "2020-11-13T03:04:15.835404Z",
     "iopub.status.idle": "2020-11-13T03:04:15.838887Z",
     "shell.execute_reply": "2020-11-13T03:04:15.838267Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(i.strip()) for i in pst_helper.frun_post_lines];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the `tr_hds_df` is a dataframe of the simulated groundwater levels extracted from the head save file,\n",
    "with other PEST-relevant columns. The `obsval` is the extracted simulated groundwater levels, the `obsnme` is the PEST observation names (encoded as `<site>_<datetime>`).  And since we added the row and col to the site names, we now have the metadata nessecary to understand where in space and in time these observations are - sweet as!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.844745Z",
     "iopub.status.busy": "2020-11-13T03:04:15.844220Z",
     "iopub.status.idle": "2020-11-13T03:04:15.846248Z",
     "shell.execute_reply": "2020-11-13T03:04:15.846713Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_hds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add these new (PEST) \"obseravtions\" to the control file.  To do that, we need the instruction file (which as also written by that nice setup routine - so thoughtful!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.849535Z",
     "iopub.status.busy": "2020-11-13T03:04:15.849086Z",
     "iopub.status.idle": "2020-11-13T03:04:15.852062Z",
     "shell.execute_reply": "2020-11-13T03:04:15.851430Z"
    }
   },
   "outputs": [],
   "source": [
    "[f for f in os.listdir(pst_helper.m.model_ws) if f.endswith(\".ins\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `pyemu.Pst.add_observations` method for this.  Important: only run this block once!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.855308Z",
     "iopub.status.busy": "2020-11-13T03:04:15.854881Z",
     "iopub.status.idle": "2020-11-13T03:04:15.869542Z",
     "shell.execute_reply": "2020-11-13T03:04:15.869970Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pst_helper.pst.add_observations(os.path.join(pst_helper.m.model_ws,\n",
    "                nam_file.replace(\".nam\",\".hds_timeseries.processed.ins\")),pst_path=\".\")\n",
    "obs = pst_helper.pst.observation_data\n",
    "obs.loc[df.index,\"obgnme\"] = df.index.map(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n",
    "obs.loc[df.index,\"weight\"] = 1.0\n",
    "obs.loc[df.index,\"obgnme\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are our new transient groundwater level observation groups.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add modpath input files, instruction files and calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First copy over all the MODPATH-related files from the base directory identified in the `b_d` variable.   We will track a single particle for forecast purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.872942Z",
     "iopub.status.busy": "2020-11-13T03:04:15.872459Z",
     "iopub.status.idle": "2020-11-13T03:04:15.879775Z",
     "shell.execute_reply": "2020-11-13T03:04:15.879133Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_files = [f for f in os.listdir(b_d) if \"mp\" in f or \"location\" in f]\n",
    "[shutil.copy2(os.path.join(b_d,f),os.path.join(pst_helper.new_model_ws,f)) for f in mp_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `frun_post_lines` property adds statements at the end of the `forward_run.py` script. In this case, it runs MODPATH using `mp6`.  We will also identify any additional temporary files that the forward run script will attempt to remove at the start of a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.882425Z",
     "iopub.status.busy": "2020-11-13T03:04:15.882007Z",
     "iopub.status.idle": "2020-11-13T03:04:15.884178Z",
     "shell.execute_reply": "2020-11-13T03:04:15.884616Z"
    }
   },
   "outputs": [],
   "source": [
    "#pst_helper.frun_post_lines.append(\"os.system('mp6 freyberg.mpsim >mp6.stdout')\")\n",
    "pst_helper.frun_post_lines.append(\"pyemu.os_utils.run('mp6 freyberg.mpsim >mp6.stdout')\")\n",
    "pst_helper.tmp_files.append(\"freyberg.mpenpt\")  # placed at top of `forward_run.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have added new commands for the forward run process, we need to re-write the `forward_run.py` script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.887309Z",
     "iopub.status.busy": "2020-11-13T03:04:15.886744Z",
     "iopub.status.idle": "2020-11-13T03:04:15.888833Z",
     "shell.execute_reply": "2020-11-13T03:04:15.889263Z"
    }
   },
   "outputs": [],
   "source": [
    "pst_helper.write_forward_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.893000Z",
     "iopub.status.busy": "2020-11-13T03:04:15.892070Z",
     "iopub.status.idle": "2020-11-13T03:04:15.896587Z",
     "shell.execute_reply": "2020-11-13T03:04:15.895892Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(i.rstrip()) for i in open('template_history/forward_run.py','r').readlines()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet!  now we have added the MODPATH bits to this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create and add an instruction file and related observations for MODPATH - we will track a single particle released need the western groundwater divide and use both its travel time and particle status as \"observations\" in the control file (well, actually, we will use these two quantities as forecasts!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.899944Z",
     "iopub.status.busy": "2020-11-13T03:04:15.899418Z",
     "iopub.status.idle": "2020-11-13T03:04:15.901485Z",
     "shell.execute_reply": "2020-11-13T03:04:15.901959Z"
    }
   },
   "outputs": [],
   "source": [
    "# write a really simple instruction file to read the MODPATH end point file\n",
    "out_file = \"freyberg.mpenpt\"\n",
    "ins_file = out_file + \".ins\"\n",
    "with open(os.path.join(pst_helper.new_model_ws,ins_file),'w') as f:\n",
    "    f.write(\"pif ~\\n\")\n",
    "    f.write(\"l7 w w w !part_status! w w !part_time!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we need to add these \"observations\" to our pest control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.908753Z",
     "iopub.status.busy": "2020-11-13T03:04:15.904048Z",
     "iopub.status.idle": "2020-11-13T03:04:15.915355Z",
     "shell.execute_reply": "2020-11-13T03:04:15.915821Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pst_helper.pst.add_observations(os.path.join(pst_helper.new_model_ws,ins_file),\n",
    "                                     os.path.join(pst_helper.new_model_ws,out_file),\n",
    "                                     pst_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to copy the original prsity arrays to the `arr_org` dir for use in the multiplier parameterization scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.918885Z",
     "iopub.status.busy": "2020-11-13T03:04:15.918462Z",
     "iopub.status.idle": "2020-11-13T03:04:15.921825Z",
     "shell.execute_reply": "2020-11-13T03:04:15.922333Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(m.nlay):\n",
    "    np.savetxt(os.path.join(pst_helper.new_model_ws,\"arr_org\",\"prsity_layer_{0}.ref\".format(k+1)),\n",
    "               np.zeros((m.nrow,m.ncol))+0.0005,fmt=\"%15.6E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final bits and bobs\n",
    "We need to set some realistic parameter bounds and account for expected (but stochastic) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.927604Z",
     "iopub.status.busy": "2020-11-13T03:04:15.925953Z",
     "iopub.status.idle": "2020-11-13T03:04:15.941921Z",
     "shell.execute_reply": "2020-11-13T03:04:15.942445Z"
    }
   },
   "outputs": [],
   "source": [
    "par = pst.parameter_data  # we inspected this guy earlier\n",
    "# properties\n",
    "tag_dict = {\"hk\":[0.1,10.0],\"vka\":[0.1,10],\"pr\":[0.5,1.5],\"rech\":[0.7,1.3]}\n",
    "for t,[l,u] in tag_dict.items():\n",
    "    t_pars = par.loc[par.parnme.apply(lambda x: t in x ),\"parnme\"]\n",
    "    par.loc[t_pars,\"parubnd\"] = u\n",
    "    par.loc[t_pars,\"parlbnd\"] = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the combinations of multipliers, we need to set a hard upper bound on `sy` and `prsity` since they have physical upper limit (note: seperate to bounds handled explicitly by pest).  This is how you set bounds on the actual model input arrays that MODFLOW will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.945693Z",
     "iopub.status.busy": "2020-11-13T03:04:15.945176Z",
     "iopub.status.idle": "2020-11-13T03:04:15.956137Z",
     "shell.execute_reply": "2020-11-13T03:04:15.956680Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_csv = os.path.join(pst_helper.new_model_ws,\"arr_pars.csv\")\n",
    "df = pd.read_csv(arr_csv,index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.961041Z",
     "iopub.status.busy": "2020-11-13T03:04:15.960574Z",
     "iopub.status.idle": "2020-11-13T03:04:15.963603Z",
     "shell.execute_reply": "2020-11-13T03:04:15.964084Z"
    }
   },
   "outputs": [],
   "source": [
    "sy_pr = df.model_file.apply(lambda x: \"sy\" in x or \"pr\" in x)\n",
    "df.loc[:,\"upper_bound\"] = np.NaN\n",
    "df.loc[sy_pr,\"upper_bound\"] = 0.4\n",
    "#rch = df.model_file.apply(lambda x: \"rech\" in x)\n",
    "#df.loc[rch,\"upper_bound\"] = 1000.0\n",
    "df.to_csv(arr_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:15.966770Z",
     "iopub.status.busy": "2020-11-13T03:04:15.966301Z",
     "iopub.status.idle": "2020-11-13T03:04:16.079237Z",
     "shell.execute_reply": "2020-11-13T03:04:16.079667Z"
    }
   },
   "outputs": [],
   "source": [
    "# table can also be written to a .tex file (report-ready!)\n",
    "df = pst.write_par_summary_table(filename=\"none\").sort_index()\n",
    "df.loc[df.index.map(lambda x: \"rech\" in x),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:16.083206Z",
     "iopub.status.busy": "2020-11-13T03:04:16.082728Z",
     "iopub.status.idle": "2020-11-13T03:04:16.129932Z",
     "shell.execute_reply": "2020-11-13T03:04:16.130430Z"
    }
   },
   "outputs": [],
   "source": [
    "pst.write_obs_summary_table(filename=\"none\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the process once (`noptmax=0`) to make sure its all plumbed up.  Pro-tip: you can use any of the `pestpp-###` binaries/executables to run `noptmax=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:16.144865Z",
     "iopub.status.busy": "2020-11-13T03:04:16.144386Z",
     "iopub.status.idle": "2020-11-13T03:04:25.572602Z",
     "shell.execute_reply": "2020-11-13T03:04:25.573112Z"
    }
   },
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-glm freyberg.pst\",cwd=pst_helper.new_model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:25.599064Z",
     "iopub.status.busy": "2020-11-13T03:04:25.577086Z",
     "iopub.status.idle": "2020-11-13T03:04:25.739136Z",
     "shell.execute_reply": "2020-11-13T03:04:25.739608Z"
    }
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(pst_helper.m.model_ws,\"freyberg.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look in the `template_history` dir, you should see a \"freyberg.rec\" file - the PESTPP-IES run record file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:25.742663Z",
     "iopub.status.busy": "2020-11-13T03:04:25.742208Z",
     "iopub.status.idle": "2020-11-13T03:04:25.751492Z",
     "shell.execute_reply": "2020-11-13T03:04:25.750838Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(i.rstrip()) for i in open('template_history/freyberg.rec','r').readlines()[-20:]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take it up a notch. We need to generate the prior parameter covariance matrix and stochastic realizations. In the author's opinion, this one of the hardest tasks for us groundwater people and also one of the most important.  The `PstFromFlopyModel` class was originally created to just to help with this task. So let's use it!  The `pst_helper` has some default geostatistical structures stored with it.  These structures use a range that is proportional to the model grid spacing and have a sill of 1.0 - using this sill is very important - it lets us later use the parameter bounds to scale the resulting covariance matrix blocks by the uncertainty implied by the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:25.767586Z",
     "iopub.status.busy": "2020-11-13T03:04:25.763796Z",
     "iopub.status.idle": "2020-11-13T03:04:26.046291Z",
     "shell.execute_reply": "2020-11-13T03:04:26.046774Z"
    }
   },
   "outputs": [],
   "source": [
    "pst_helper.grid_geostruct.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:26.060485Z",
     "iopub.status.busy": "2020-11-13T03:04:26.057469Z",
     "iopub.status.idle": "2020-11-13T03:04:42.261966Z",
     "shell.execute_reply": "2020-11-13T03:04:42.262425Z"
    }
   },
   "outputs": [],
   "source": [
    "if pst_helper.pst.npar < 35000: #if you have more than about 35K pars, the cov matrix becomes hard to handle\n",
    "    # build out the full cov matrix and write it to a compressed binary file\n",
    "    cov = pst_helper.build_prior(fmt=\"coo\",filename=os.path.join(pst_helper.new_model_ws,\"prior_cov.jcb\"))\n",
    "    # mask for plotting\n",
    "    cov = np.ma.masked_where(cov.x==0,cov.x)\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = plt.subplot(111)\n",
    "        ax.imshow(cov)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it: a full geostatistically-correlated block-diagonal covariance matrix.  Let's take a moment to soak that up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can make a draw from the prior parameter covariance matrix to form a prior parameter ensemble\n",
    "\n",
    "The `pst_helper.draw()` method is very efficient, especially when the number of parameters is >35K.  It avoids forming the full cov matrix and instead operates block by block and, for grid-scale parameters, switches to 2-D spectral simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:42.276961Z",
     "iopub.status.busy": "2020-11-13T03:04:42.273105Z",
     "iopub.status.idle": "2020-11-13T03:04:46.471688Z",
     "shell.execute_reply": "2020-11-13T03:04:46.472225Z"
    }
   },
   "outputs": [],
   "source": [
    "pe = pst_helper.draw(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that parameters are treated in parameter group (`pargp`) blocks for this ensemble generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always a good idea to inspect the parameter ensemble for reasonableness! Can do via slicing and dicing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:46.475717Z",
     "iopub.status.busy": "2020-11-13T03:04:46.475230Z",
     "iopub.status.idle": "2020-11-13T03:04:46.501605Z",
     "shell.execute_reply": "2020-11-13T03:04:46.502108Z"
    }
   },
   "outputs": [],
   "source": [
    "pe.iloc[-10:-5,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at parameters by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:46.505590Z",
     "iopub.status.busy": "2020-11-13T03:04:46.505104Z",
     "iopub.status.idle": "2020-11-13T03:04:53.118791Z",
     "shell.execute_reply": "2020-11-13T03:04:53.119250Z"
    }
   },
   "outputs": [],
   "source": [
    "par = pst_helper.pst.parameter_data\n",
    "pyemu.plot_utils.ensemble_helper(pe,plot_cols=par.groupby(\"pargp\").groups,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts? Do these look reasonable? We see log-normal distributions for log-transformed parameters, e.g., hk... looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to enforce parameter bounds and save this ensemble for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:53.197411Z",
     "iopub.status.busy": "2020-11-13T03:04:53.196980Z",
     "iopub.status.idle": "2020-11-13T03:04:54.177825Z",
     "shell.execute_reply": "2020-11-13T03:04:54.178278Z"
    }
   },
   "outputs": [],
   "source": [
    "pe.enforce()  # always a good idea!\n",
    "pe.to_binary(os.path.join(pst_helper.new_model_ws,\"prior.jcb\"))\n",
    "pst_helper.pst.write(os.path.join(pst_helper.m.model_ws,nam_file.replace(\".nam\",\".pst\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set forecast names - just a few for FOSM later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:54.183769Z",
     "iopub.status.busy": "2020-11-13T03:04:54.183357Z",
     "iopub.status.idle": "2020-11-13T03:04:54.188687Z",
     "shell.execute_reply": "2020-11-13T03:04:54.189121Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = pst_helper.pst.observation_data\n",
    "dts = pd.to_datetime(pst_helper.m.start_datetime) + pd.to_timedelta(np.cumsum(pst_helper.m.dis.perlen.array),unit='d')\n",
    "dts_str = list(dts.map(lambda x: x.strftime(\"%Y%m%d\")).values)\n",
    "dry_dt = dts_str[dry_kper]\n",
    "print(dry_dt)\n",
    "swgw_forecasts = obs.loc[obs.obsnme.apply(lambda x: \"fa\" in x and (\"hw\" in x or \"tw\" in x) and dry_dt in x),\"obsnme\"].tolist()\n",
    "#print(swgw_forecasts)\n",
    "hds_fore_name = \"hds_00_{0:03d}_{1:03d}_{2:03d}\".format(int(pst_helper.m.nrow/3),int(pst_helper.m.ncol/10)\n",
    "                                                       ,dry_kper)\n",
    "print(hds_fore_name)\n",
    "hds_forecasts = obs.loc[obs.obsnme.apply(lambda x: hds_fore_name in x),\"obsnme\"].tolist()\n",
    "forecasts = swgw_forecasts\n",
    "forecasts.extend(hds_forecasts)\n",
    "forecasts.append(\"part_time\")\n",
    "forecasts.append(\"part_status\")\n",
    "pst_helper.pst.pestpp_options[\"forecasts\"] = forecasts\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:54.201224Z",
     "iopub.status.busy": "2020-11-13T03:04:54.194357Z",
     "iopub.status.idle": "2020-11-13T03:04:54.732130Z",
     "shell.execute_reply": "2020-11-13T03:04:54.732547Z"
    }
   },
   "outputs": [],
   "source": [
    "pst_helper.pst.write(os.path.join(pst_helper.m.model_ws,nam_file.replace(\".nam\",\".pst\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"This is not the python command you are looking for\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:54.735289Z",
     "iopub.status.busy": "2020-11-13T03:04:54.734861Z",
     "iopub.status.idle": "2020-11-13T03:04:55.677659Z",
     "shell.execute_reply": "2020-11-13T03:04:55.678100Z"
    }
   },
   "outputs": [],
   "source": [
    "prep_deps.prep_forecasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:04:55.680875Z",
     "iopub.status.busy": "2020-11-13T03:04:55.680472Z",
     "iopub.status.idle": "2020-11-13T03:05:04.473148Z",
     "shell.execute_reply": "2020-11-13T03:05:04.473674Z"
    }
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies {0}\".format(nam_file.replace(\".nam\",\".pst\")),cwd=pst_helper.m.model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:05:04.478287Z",
     "iopub.status.busy": "2020-11-13T03:05:04.477789Z",
     "iopub.status.idle": "2020-11-13T03:05:04.690423Z",
     "shell.execute_reply": "2020-11-13T03:05:04.690852Z"
    }
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(pst_helper.m.model_ws,\"freyberg.pst\"))\n",
    "pst.res.loc[pst.forecast_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:05:04.694061Z",
     "iopub.status.busy": "2020-11-13T03:05:04.693588Z",
     "iopub.status.idle": "2020-11-13T03:05:06.264053Z",
     "shell.execute_reply": "2020-11-13T03:05:06.264561Z"
    }
   },
   "outputs": [],
   "source": [
    "lst = flopy.utils.MfListBudget(os.path.join(pst_helper.m.model_ws,nam_file.replace(\".nam\",\".list\")))\n",
    "df = lst.get_dataframes(diff=True,start_datetime=pst_helper.m.start_datetime)[0]\n",
    "df.plot(kind=\"bar\",figsize=(30,30), grid=True,subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demystifying the multiplier parameter process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:05:06.272305Z",
     "iopub.status.busy": "2020-11-13T03:05:06.271807Z",
     "iopub.status.idle": "2020-11-13T03:05:06.273456Z",
     "shell.execute_reply": "2020-11-13T03:05:06.274006Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_and_plot_hk(real):\n",
    "    # replace the par values in the control file\n",
    "    pst.parameter_data.loc[:,\"parval1\"] = pe.loc[real,pst.par_names]\n",
    "    # save the updated control file\n",
    "    pst.write(os.path.join(pst_helper.new_model_ws,\"test.pst\"))\n",
    "    # run a single model run to generate the multipliers and inputs\n",
    "    pyemu.os_utils.run(\"pestpp-ies.exe test.pst\",cwd=pst_helper.new_model_ws)\n",
    "\n",
    "    # load the arrays\n",
    "    base_arr = np.log10(np.loadtxt(os.path.join(pst_helper.new_model_ws,\"arr_org\",\"hk_Layer_1.ref\")))\n",
    "    pp_arr = np.log10(np.loadtxt(os.path.join(pst_helper.new_model_ws,\"arr_mlt\",\"hk0.dat_pp\")))\n",
    "    gr_arr = np.log10(np.loadtxt(os.path.join(pst_helper.new_model_ws,\"arr_mlt\",\"hk3.dat_gr\")))\n",
    "    cn_arr = np.log10(np.loadtxt(os.path.join(pst_helper.new_model_ws,\"arr_mlt\",\"hk6.dat_cn\")))\n",
    "    in_arr = np.log10(np.loadtxt(os.path.join(pst_helper.new_model_ws,\"hk_Layer_1.ref\")))\n",
    "    arrs = [base_arr,cn_arr,pp_arr,gr_arr,in_arr]\n",
    "    \n",
    "    labels = [\"log10 base\",\"log10 constant\",\"log10 pilot points\",\"log10 grid\",\"log10 resulting input\"]\n",
    "    # mask with ibound\n",
    "    ib = m.bas6.ibound[0].array\n",
    "    for i,arr in enumerate(arrs):\n",
    "        arr[ib==0] = np.NaN\n",
    "    \n",
    "    fig,axes = plt.subplots(1,5,figsize=(20,5))\n",
    "    \n",
    "    # work out the multiplier min and max\n",
    "    vmin1 = min([np.nanmin(a) for a in arrs[1:-1]])\n",
    "    vmax1 = max([np.nanmax(a) for a in arrs[1:-1]])\n",
    "    \n",
    "    # plot each array\n",
    "    for i,(ax,arr,label) in enumerate(zip(axes,arrs,labels)):\n",
    "        if i not in [0,len(arrs)-1]:  \n",
    "            cb = ax.imshow(arr,vmin=vmin1,vmax=vmax1)\n",
    "        else:\n",
    "            cb = ax.imshow(arr)\n",
    "        ax.set_title(label)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        plt.colorbar(cb,ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:05:06.282027Z",
     "iopub.status.busy": "2020-11-13T03:05:06.281563Z",
     "iopub.status.idle": "2020-11-13T03:05:16.002450Z",
     "shell.execute_reply": "2020-11-13T03:05:16.002879Z"
    }
   },
   "outputs": [],
   "source": [
    "run_and_plot_hk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T03:05:16.009599Z",
     "iopub.status.busy": "2020-11-13T03:05:16.009197Z",
     "iopub.status.idle": "2020-11-13T03:05:25.713689Z",
     "shell.execute_reply": "2020-11-13T03:05:25.714661Z"
    }
   },
   "outputs": [],
   "source": [
    "run_and_plot_hk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
